{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Author: Harry Yau\n",
    "\n",
    "Date: Aug 28, 2019"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import glob as glob\n",
    "import pickle\n",
    "import re\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def standardize_colnames(colnames):\n",
    "    for i, val in enumerate(colnames):\n",
    "        if 'Departure temperature' in val:\n",
    "            colnames[i] = 'Departure temperature'\n",
    "        if 'Return temperature' in val:\n",
    "            colnames[i] = 'Return temperature'\n",
    "        if 'Stopover duration' in val:\n",
    "            colnames[i] = 'Stopover duration'\n",
    "        if 'Membership type' in val:\n",
    "            colnames[i] = 'Membership Type'\n",
    "        if 'Formula' in val:\n",
    "            colnames[i] = 'Membership Type'\n",
    "            \n",
    "    return(colnames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle_folder = 'pickle'\n",
    "\n",
    "#Data that has all the bike station info. It was pre-processed.\n",
    "station_info_df = pd.read_csv('data/station_data.csv', dtype={'id': str, 'name': str, 'lat': float, 'lon': float, 'total_slots':int})\n",
    "\n",
    "#Loading pre-loaded CSV files that was loaded into memory and saved as a pickle file. Please check another notebook\n",
    "filename = 'loaded_mobi_data.pkl'\n",
    "infile = open('pickle' + '/'+ filename, 'rb')\n",
    "data_list = pickle.load(infile)\n",
    "infile.close()\n",
    "\n",
    "#Filter the data by standardizing the columns. The provided CSV files all have different column names, and different data.\n",
    "col_names_ref = data_list[0].columns\n",
    "col_names_ref_list = standardize_colnames(list(col_names_ref))\n",
    "\n",
    "for i, df in enumerate(data_list):\n",
    "    data_list[i].columns = standardize_colnames(list(df.columns))\n",
    "for i, d in enumerate(data_list):\n",
    "    data_list[i] = d.reindex(columns=col_names_ref_list)\n",
    "\n",
    "del col_names_ref, col_names_ref_list\n",
    "    \n",
    "#Combine all the data frames in the list.\n",
    "combined_df = pd.concat(data_list, axis=0)\n",
    "combined_df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "del data_list\n",
    "\n",
    "#drop rows with departure station and return station being NA\n",
    "combined_df = combined_df[~combined_df['Departure station'].isna()]\n",
    "combined_df = combined_df[~combined_df['Return station'].isna()]\n",
    "\n",
    "#To save space in memory, splitting the Departure and Return station names so that it only shows the\n",
    "temp_dep=[]\n",
    "temp_ret=[]\n",
    "\n",
    "for i in combined_df['Departure station']:\n",
    "    temp = re.split('\\s', i, 1)\n",
    "    temp_dep.append(temp[0])\n",
    "    \n",
    "for i in combined_df['Return station']:\n",
    "    temp = re.split('\\s', i, 1)\n",
    "    temp_ret.append(temp[0])\n",
    "\n",
    "combined_df['Departure station'] = temp_dep\n",
    "combined_df['Return station'] = temp_ret\n",
    "\n",
    "del temp_dep, temp_ret\n",
    "\n",
    "#Remove non-existent stations. Pair up with master station list.\n",
    "vec = combined_df['Departure station'].isin(station_info_df['id'])\n",
    "combined_df = combined_df[vec]\n",
    "\n",
    "vec = combined_df['Return station'].isin(station_info_df['id'])\n",
    "combined_df = combined_df[vec]\n",
    "\n",
    "#Convert to datetime..\n",
    "combined_df['Departure'] = pd.to_datetime(combined_df['Departure'])\n",
    "combined_df['Return'] = pd.to_datetime(combined_df['Return'])\n",
    "\n",
    "del vec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check the Size of the data frame for sanity reasons."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1387272, 15)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adding Features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adding 2 useful features: Adjusted Duaration and Average Speed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_df['Adj Duration (sec.)'] = (combined_df['Duration (sec.)']-combined_df['Stopover duration'])\n",
    "\n",
    "combined_df['Average speed (km/h)'] = (combined_df['Covered distance (m)']/1000) / \\\n",
    "    ((combined_df['Adj Duration (sec.)'] )/3600)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
